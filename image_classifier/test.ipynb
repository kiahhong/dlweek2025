{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import ViTImageProcessor\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224  # ViT use 224x224 images\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "path = r\"/content/drive/MyDrive/testing - Copy\"\n",
    "\n",
    "# Load dataset\n",
    "train_data = datasets.ImageFolder(root=path + \"/train\", transform=train_transforms)\n",
    "val_data   = datasets.ImageFolder(root=path + \"/test\", transform=val_transforms)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = train_data.classes\n",
    "print(class_names)  # e.g., ['real', 'fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification, AutoImageProcessor\n",
    "\n",
    "# Load pre-trained ViT model and image processor\n",
    "model_name = \"google/vit-base-patch16-224\"  # ViT Base, patch size 16, 224x224 images\n",
    "model = ViTForImageClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "print(\"Expected image mean:\", processor.image_mean, \"std:\", processor.image_std)\n",
    "\n",
    "for param in model.vit.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)          \n",
    "        logits = outputs.logits          \n",
    "        loss = criterion(logits, labels) \n",
    "        loss.backward()                  \n",
    "        optimizer.step()                 \n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    epoch_loss = running_loss / len(train_data)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            logits = outputs.logits\n",
    "            _, preds = torch.max(logits, dim=1)    # Predicted class indices\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {epoch_loss:.4f} - Val Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"vit_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "repo_name = \"O-ww-O/custom-vit\"  # Change this to your desired repo name\n",
    "\n",
    "api = HfApi()\n",
    "api.create_repo(repo_name, exist_ok=True)\n",
    "\n",
    "model.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"O-ww-O/custom-vit\"\n",
    "model = ViTForImageClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Ensure model is in eval mode and on CPU or GPU as available\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "def predict_image(image_path):\n",
    "    \"\"\"Predicts whether an image is real or AI-generated.\"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    # Apply the same transforms as validation (resize, tensor, normalize)\n",
    "    img_tensor = val_transforms(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        logits = outputs.logits\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "    label = class_names[pred]\n",
    "    return label\n",
    "\n",
    "print(predict_image(\"/content/drive/MyDrive/testing - Copy/test/REAL/0003 (5).jpg\"))  # prints \"real\" or \"fake\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlweek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
